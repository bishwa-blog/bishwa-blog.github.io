<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home | Brian Zhang</title>
    <link>https://brianzhang01.github.io/</link>
    <description>Recent content on Home | Brian Zhang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://brianzhang01.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Subtle Observations on Range Queries</title>
      <link>https://brianzhang01.github.io/2019/01/subtle-observations-on-range-queries/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2019/01/subtle-observations-on-range-queries/</guid>
      <description>For my current research, I’ve had to read Kelleher et al.’s excellent msprime paper (2016) for simulating genetic sequences under the coalescent with recombination. A small trick that is used in their algorithm is the data structure of a Fenwick tree or binary indexed tree. Since I also have a side interest in competitive programming (mainly through USACO and Project Euler), I took a bit more time to learn this data structure.</description>
    </item>
    
    <item>
      <title>Missing Heritability and Microaggressions</title>
      <link>https://brianzhang01.github.io/2018/10/missing-heritability-and-microaggressions/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2018/10/missing-heritability-and-microaggressions/</guid>
      <description>Missing heritability is like microaggressions: many seemingly insignificant effects can add up.
Two weeks ago, as I was taking a journey back to London Heathrow / Oxford, I came across a small connection in a journal article and a podcast. It was a nice moment of seeing two ideas click together.
The podcast, which came second, was an episode of Nomad, a British podcast discussing Christian faith outside the institutional church.</description>
    </item>
    
    <item>
      <title>Random Graphs and Giant Components</title>
      <link>https://brianzhang01.github.io/2018/07/random-graphs-and-giant-components/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2018/07/random-graphs-and-giant-components/</guid>
      <description>This post will introduce some of the ideas behind random graphs, a very exciting area of current probability research. As has been a theme in my posts so far, I try to emphasize a reproducible, computational example. In this case, we’ll be looking at the “giant component” and how that arises in random graphs.
There’s a lot more than this example that I find exciting, so I’ve deferred a longer discussion on random graphs to the end of this post, with a lot of references for the interested reader.</description>
    </item>
    
    <item>
      <title>Distributions with SymPy</title>
      <link>https://brianzhang01.github.io/2018/04/distributions-with-sympy/</link>
      <pubDate>Wed, 04 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2018/04/distributions-with-sympy/</guid>
      <description>Any good statistics student will need to do some integrals in her / his life. While I generally feel comfortable with simple integrals, I thought it might be worth setting up a workflow to help automate this process!
Previously, especially coming from a physics background, I’ve worked a lot with Mathematica, an advanced version of the software available online as WolframAlpha. Mathematica is extremely powerful, but it’s not open-source and comes with a hefty license, so I decided to research alternatives.</description>
    </item>
    
    <item>
      <title>Clustering with K-Means and EM</title>
      <link>https://brianzhang01.github.io/2018/01/clustering-with-k-means-and-em/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2018/01/clustering-with-k-means-and-em/</guid>
      <description>Introduction K-means and EM for Gaussian mixtures are two clustering algorithms commonly covered in machine learning courses. In this post, I’ll go through my implementations on some sample data.
I won’t be going through much theory, as that can be easily found elsewhere. Instead I’ve focused on highlighting the following:
 Pretty visualizations in ggplot, with the helper packages deldir, ellipse, and knitr for animations.
 Structural similarities in the algorithms, by splitting up K-means into an E and M step.</description>
    </item>
    
    <item>
      <title>Statistics / ML Books</title>
      <link>https://brianzhang01.github.io/2017/11/statistics-ml-books/</link>
      <pubDate>Sat, 25 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2017/11/statistics-ml-books/</guid>
      <description>At the start of the last post, I talked briefly about courses I’ve been working through. Here are some follow-up thoughts on good books!1
This post will focus on textbooks with a machine learning focus. I’ve read less of the classic statistics textbooks, as I hadn’t specialized much in statistics until my PhD. However, these are a few texts that are on my radar to consult:
 The Elements of Statistical Learning: Data Mining, Inference, and Prediction (2009, 2nd Ed.</description>
    </item>
    
    <item>
      <title>Polynomial Regression</title>
      <link>https://brianzhang01.github.io/2017/11/polynomial-regression/</link>
      <pubDate>Thu, 09 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2017/11/polynomial-regression/</guid>
      <description>Introduction: side courses As a PhD student in the UK system, I was expecting a lot less coursework, with my first year diving straight into research. However, there are still a lot of gaps in my knowledge, so I hope to always be on the lookout for learning opportunities, including side classes.
At the moment, I’m hoping to follow along with these three courses and do some assignments from time to time:</description>
    </item>
    
    <item>
      <title>Blogging Aims</title>
      <link>https://brianzhang01.github.io/2017/11/blogging-aims/</link>
      <pubDate>Sat, 04 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2017/11/blogging-aims/</guid>
      <description>Hi there, and thanks for stopping by! In this post, I briefly introduce my current ideas for this blog and say a bit about myself.
As of September, I&amp;rsquo;ve been a first-year PhD student at Oxford&amp;rsquo;s Statistics department. I received my bachelor&amp;rsquo;s in Physics from Harvard in 2015, and after working for two years am excited to be back in an academic setting. Part of this transition means more freedom and a lot more self-structured learning time.</description>
    </item>
    
  </channel>
</rss>