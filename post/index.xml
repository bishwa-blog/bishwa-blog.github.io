<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Home | Brian Zhang</title>
    <link>https://brianzhang01.github.io/post/</link>
    <description>Recent content in Posts on Home | Brian Zhang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Jan 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://brianzhang01.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Clustering with K-Means and EM</title>
      <link>https://brianzhang01.github.io/2018/01/clustering-with-k-means-and-em/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2018/01/clustering-with-k-means-and-em/</guid>
      <description>Introduction K-means and EM for Gaussian mixtures are two clustering algorithms commonly covered in machine learning courses. In this post, I’ll go through my implementations on some sample data.
I won’t be going through much theory, as that can be easily found elsewhere. Instead I’ve focused on highlighting the following:
 Pretty visualizations in ggplot, with the helper packages deldir, ellipse, and knitr for animations.
 Structural similarities in the algorithms, by splitting up K-means into an E and M step.</description>
    </item>
    
    <item>
      <title>Statistics / ML Books</title>
      <link>https://brianzhang01.github.io/2017/11/statistics-ml-books/</link>
      <pubDate>Sat, 25 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2017/11/statistics-ml-books/</guid>
      <description>At the start of the last post, I talked briefly about courses I’ve been working through. Here are some follow-up thoughts on good books!1
This post will focus on textbooks with a machine learning focus. I’ve read less of the classic statistics textbooks, as I hadn’t specialized much in statistics until my PhD. However, these are a few texts that are on my radar to consult:
 The Elements of Statistical Learning: Data Mining, Inference, and Prediction (2009, 2nd Ed.</description>
    </item>
    
    <item>
      <title>Polynomial Regression</title>
      <link>https://brianzhang01.github.io/2017/11/polynomial-regression/</link>
      <pubDate>Thu, 09 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2017/11/polynomial-regression/</guid>
      <description>Introduction: side courses As a PhD student in the UK system, I was expecting a lot less coursework, with my first year diving straight into research. However, there are still a lot of gaps in my knowledge, so I hope to always be on the lookout for learning opportunities, including side classes.
At the moment, I’m hoping to follow along with these three courses and do some assignments from time to time:</description>
    </item>
    
    <item>
      <title>Blogging Aims</title>
      <link>https://brianzhang01.github.io/2017/11/blogging-aims/</link>
      <pubDate>Sat, 04 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://brianzhang01.github.io/2017/11/blogging-aims/</guid>
      <description>Hi there, and thanks for stopping by! In this post, I briefly introduce my current ideas for this blog and say a bit about myself.
As of September, I&amp;rsquo;ve been a first-year PhD student at Oxford&amp;rsquo;s Statistics department. I received my bachelor&amp;rsquo;s in Physics from Harvard in 2015, and after working for two years am excited to be back in an academic setting. Part of this transition means more freedom and a lot more self-structured learning time.</description>
    </item>
    
  </channel>
</rss>